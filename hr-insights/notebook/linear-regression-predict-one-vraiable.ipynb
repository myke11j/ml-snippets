{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting `last_evaluation` of employee by `satisfaction_level` from HR dataset of 14999 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lists are to save theta and mean square error history. Later will be used to plot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0List = []\n",
    "theta1List = []\n",
    "gradientList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../HR_comma_sep.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper paramters\n",
    "learning_rate = 0.01\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using for sales employees\n",
    "df = df[ df['Department'] == 'sales' ]\n",
    "df = df.reindex(pd.RangeIndex(df.index.max() + 1)).ffill()\n",
    "#  df = df.iloc[0:100,0:10] for using only 100 employees\n",
    "[m, n] = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['satisfaction_level']\n",
    "y = df['last_evaluation']\n",
    "# y = mx + b (slope formula) ~ theta1.x + theta0\n",
    "theta = [0, 0] # inital slope and y-itercept for hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CostClass`will be used store set of thetas and cost and in the end, we will fetch the record with smalled cost (mean square error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostClass(object):\n",
    "    def __init__(self, cost, theta0, theta1):\n",
    "        self.cost = cost\n",
    "        self.theta0 = theta0\n",
    "        self.theta1 = theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(m, theta, x, y):\n",
    "    hypothesis = theta[0] - np.dot(x, theta[1])\n",
    "    loss = hypothesis - y\n",
    "    cost = np.sum(loss ** 2) / (2 * m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costThetaList = []\n",
    "\n",
    "# m denotes the number of examples here, not the number of features\n",
    "def gradientDescent(x, y, theta, learning_rate, num_iterations):\n",
    "    m = len(x)\n",
    "    theta0Gradient = 0; # initial value\n",
    "    theta1Gradient = 0; # initial value\n",
    "    [theta0, theta1] = theta\n",
    "    for i in range(0, num_iterations):\n",
    "        cost = computeCost(m, theta, x, y)\n",
    "        costThetaList.append(CostClass(cost, theta0, theta1)) # adding history data in set for fetching the minimum later\n",
    "        \n",
    "        # Appending value in lists for plotting the graph later-on\n",
    "        gradientList.append(cost)\n",
    "        theta0List.append(theta0)\n",
    "        theta1List.append(theta1)\n",
    "        \n",
    "        # print(\"Iteration %d | Cost: %f | theta %f %f\" % (i, cost,theta0, theta1))\n",
    "        theta0Gradient += -(2/m) * (y[i] - ((theta1 * x[i]) + theta0))\n",
    "        theta1Gradient += -(2/m) * x[i] * (y[i] - ((theta1 * x[i]) + theta1))\n",
    "        theta0 = theta0 - (learning_rate * theta0Gradient)\n",
    "        theta1 = theta1 - (learning_rate * theta1Gradient)\n",
    "        theta = [theta0, theta1]\n",
    "    return [theta0, theta1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting gradient descent at b = %d, m = %d, error = %f\" % (theta[0], theta[1], computeCost(m, theta, X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running...\")\n",
    "theta = gradientDescent(X, y, theta, learning_rate, num_iterations)\n",
    "\n",
    "# Sort the data in ascending wrt mean square error\n",
    "costThetaList.sort(key=lambda x: x.cost, reverse=False)\n",
    "print(\"After %d iterations b = %f, m = %f, error = %f\" % (num_iterations, costThetaList[0].theta0, costThetaList[0].theta1, costThetaList[0].cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph from list we declared above. This is showing gradient descent of cost value wrt theta0 (y-intercept) and theat1 (slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(dpi=120)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(theta1List, theta0List, gradientList, color='green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
